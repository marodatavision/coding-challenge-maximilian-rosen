# ğŸ” RAG-PDF-Suchsystem mit LLM-UnterstÃ¼tzung

Dieses Projekt ist eine prototypische Implementierung einer Retrieval-Augmented-Generation-(RAG)-Anwendung, die es ermÃ¶glicht, strukturierte Anfragen gegen einen PDF-Korpus zu stellen. Als LLM kommt die OpenAI API zum Einsatz. Die Anwendung ist vollstÃ¤ndig dockerisiert und sofort lauffÃ¤hig.

---

## ğŸš€ Schnellstart mit Docker

### ğŸ”§ Voraussetzungen
- Docker
- (Optional) Python 3.11+ & [Poetry](https://python-poetry.org) â€“ nur bei lokalem Setup

---

### ğŸ› ï¸ Setup

1. **Repository klonen**  
   ```bash
   git clone <repo-url>
   cd <repo-name>
   ```

2. **Umgebungsvariablen setzen**  
   Kopiere die Beispieldatei:
   ```bash
   cp .env.example .env -> linux
   copy .env.example .env -> windows
   ```
   Trage deinen OpenAI API Key in `.env` ein:

   ```env
   OPENAI_API_KEY=sk-...
   ```

3. **Docker starten**

   - **Produktivmodus (CLI-Nutzung):**
     ```bash
     docker compose run --rm rag-prod
     ```

     Beispielabfrage (voreingestellt in `docker-compose.yml`):
     ```text
     Was ist die Farbtemperatur von SIRIUS HRI 330W 2/CS 1/SKU?
     ```

   - **Testmodus:**
     ```bash
     docker compose run --rm rag-test
     ```

---

## ğŸ§ª Beispielanfragen (Teil 2)

| Beispielanfrage                                                                 | Beschreibung                                          |
|----------------------------------------------------------------------------------|--------------------------------------------------------|
| Was ist die Farbtemperatur von SIRIUS HRI 330W 2/CS 1/SKU?                      | Technisches Attribut extrahieren                      |
| Welche Leuchten sind gut fÃ¼r die Ausstattung im Operationssaal geeignet?        | Semantische, kontextbasierte Suche                    |
| Gib mir alle Leuchtmittel mit â‰¥ 1000 Watt und > 400 Stunden Lebensdauer         | Kriterienbasierte Filterung                          |
| Welche Leuchte hat die primÃ¤re Erzeugnisnummer 4062172212311?                   | ID-basierte Suche (Produktdatenbank)                 |

---

## ğŸ—‚ï¸ Projektstruktur

```
.
â”œâ”€â”€ .env
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ Dockerfile_poetry
â”œâ”€â”€ gdrive_service_account.json.example
â”œâ”€â”€ poetry.lock
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ tree_structur.txt
â”œâ”€â”€ .pytest_cache/
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ CACHEDIR.TAG
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ v/
â”‚       â””â”€â”€ cache/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â”œâ”€â”€ io/
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ vectorstore/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”œâ”€â”€ entrypoints/
â”‚   â”‚   â””â”€â”€ cli.py
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ __pycache__/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pdfs/
â”‚       â”œâ”€â”€ ZMP_1004795.pdf
â”‚       â”œâ”€â”€ ZMP_1006242.pdf
â”‚       â”œâ”€â”€ ZMP_1006707.pdf
â”‚       â””â”€â”€ ...
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ adapters/
â”‚   â”œâ”€â”€ core/
â”‚   â””â”€â”€ services/
```

---

## ğŸ“ˆ Skalierung (Antwort zu Teil 3)

Wenn das System auf **10.000+ PDFs** erweitert werden soll, sind folgende Schritte erforderlich:

| Bereich            | MaÃŸnahme                                                                 |
|--------------------|--------------------------------------------------------------------------|
| **Retrieval**      | Einsatz einer Vektordatenbank wie **FAISS**, **Chroma**, **Weaviate**    |
| **Embedding**      | Vorab-Indexierung aller Chunks; Caching von Embeddings                   |
| **Performance**    | Asynchrone Verarbeitung, ggf. Batch-Indexierung & Task-Queues            |
| **Speicherung**    | Nutzung persistenter Backends (z.â€¯B. SQLite, FAISS mit On-Disk-Modus)    |
| **Antwortzeit**    | Einsatz von Memory-basierten Indexen + Parallelisierung                  |
| **Horizontale Skalierung** | Aufteilung in Microservices (z.â€¯B. PDF-Loader, Retriever, LLM-Caller)   |

---

## ğŸ“„ Lizenz und Hinweise

Dieses Projekt wurde im Rahmen einer technischen Challenge entwickelt und ist nicht fÃ¼r den produktiven Einsatz bestimmt. Der Zugriff auf OpenAI-Dienste erfordert einen gÃ¼ltigen API-Key.